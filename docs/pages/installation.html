<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>Generic - Editorial by HTML5 UP</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="../assets/css/main.css"/>
    <link rel="stylesheet" href="../assets/css/codemirror.min.css">
    <link rel="stylesheet" href="../assets/css/monokai.min.css">
    <link rel="stylesheet" href="../assets/css/foldgutter.min.css">
    <link rel="stylesheet" href="../assets/css/codemirror-custom.css">
    <link rel="stylesheet" href="../assets/css/zenburn.min.css">
    <script src="../assets/js/codemirror.min.js"></script>
    <script src="../assets/js/python.min.js"></script>
    <script src="../assets/js/json-lint.min.js"></script>
    <script src="../assets/js/foldcode.min.js"></script>
    <script src="../assets/js/foldgutter.min.js"></script>
    <script src="../assets/js/brace-fold.min.js"></script>
    <script src="../assets/js/codemirror-custom.js"></script>
</head>

<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

    <!-- Main -->
    <div id="main">
        <div class="inner">

            <!-- Header -->
            <header id="header">
                <a href="../index.html" class="logo"><strong>Yacana</strong>, powering open source LLMs</a>
                <ul class="icons">
                    <li><a href="https://x.com/RSoftwares_ofc" class="icon brands fa-twitter"><span class="label">Twitter</span></a>
                    </li>
                    <li><a href="https://medium.com/@docteur_rs" class="icon brands fa-medium-m"><span class="label">Medium</span></a>
                    </li>
                    <li><a href="https://www.youtube.com/channel/UCvi7R0CRmtxhWOVw62XteTw"
                           class="icon brands fa-youtube"><span class="label">Medium</span></a></li>
                    <li><a href="https://github.com/rememberSoftwares/yacana" class="icon brands fa-github"><span
                            class="label">Github</span></a></li>
                </ul>
            </header>

            <!-- Content -->
            <section>
                <header class="main">
                    <h1 id="installing-ollama">I. Installation</h1>
                </header>

                <span class="image main"><img src="../images/installation.jpg"
                                              alt="Yacana and Ollama installation"/></span>


                <h2>Installing Ollama</h2>
                <p style="text-align: center;"><img
                        src="https://github.com/user-attachments/assets/f3c45d0e-efca-4853-8237-3e56d90e1747"
                        alt="image"></p>
                <p>The current release of Yacana was made to work with <strong>Ollama</strong>. We will extend
                    support to all other
                    major inference servers in the next update.<br>
                    The first step is to install Ollama. It will be used to serve AI models with an HTTP API. <br>
                    If your computer is performant enough you can use it to run LLMs directly on your machine.
                    Ollama is a great inference server and the most simple to
                    install.
                </p>
                <p>
                    Click <a href="https://ollama.com/download">here</a> to get the latest release.<br>
                </p>
                <span>Ollama is:</span>
                <ul>
                    <li>Compatible with all operating systems Windows/Mac/Linux ;</li>
                    <li>Installed in seconds using one command ;</li>
                    <li>Has a great CLi that even a 4-year-old can use to download models ;</li>
                    <li>Has tons of tutorials out there if you run into any trouble ;</li>
                </ul>
                <p class="icon solid fa-info-circle"> You can connect Yacana to a remote Ollama instance. Read
                    forward.</p>

                <hr class="major"/>

                <h2 id="choosing-an-llm-model">Choosing an LLM model</h2>
                <p>After Ollama is installed you can browse the list of available LLMs on the <a
                        href="https://ollama.com/library">Ollama website</a> and download any model you want (or
                    your computer can
                    deal with).<br>
                    For reference, if you don't know what LLM model to choose (we've all been there) here is a list
                    of models you
                    can try out on consumer hardware:</p>
                <div class="table-wrapper">
                    <table class="alt">
                        <thead>
                        <tr>
                            <th>Computer power</th>
                            <th style="text-align:center">LLM models name to try</th>
                            <th style="text-align:center">LLM quality</th>
                        </tr>
                        </thead>
                        <tbody>
                        <tr>
                            <td><strong>Out of this world</strong> <em>(RTX 4090 / 64 GB RAM)</em></td>
                            <td style="text-align:center">'llama3.1:70b' or 'mixtral:8x22b'</td>
                            <td style="text-align:center">Excellent reasoning and instruction following.</td>
                        </tr>
                        <tr>
                            <td><strong>Epic</strong> <em>(RTX 4090 / 32 GB RAM)</em></td>
                            <td style="text-align:center">'llama3.1:8b' or 'dolphin-mixtral:8x7b' or
                                'dolphin-mixtral:8x7b-v2.5-q6_K'
                            </td>
                            <td style="text-align:center">Good reasoning and instruction following. (q6_K model
                                should be less
                                consuming than the default Mixtral if you have any issues)
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Gamer</strong> <em>(GTX 1080TI / 16 GB RAM)</em></td>
                            <td style="text-align:center">'llama3.1:8b' or 'mistral:7b'</td>
                            <td style="text-align:center">Llama still works but is slower. Expect limited
                                reasoning
                                and no more than
                                2 complex instructions at a time
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Potato</strong></td>
                            <td style="text-align:center">'phi:2.7b' or 'phi3:3.8b' or 'tinyllama:1.1b'</td>
                            <td style="text-align:center">Almost no reasoning, incapable of following more than
                                1
                                instruction at a
                                time, English bound only ; Dumb as a stone
                            </td>
                        </tr>
                        </tbody>
                    </table>
                </div>
                <p>If you have access to a GPU VM with A LOT of RAM then you should try the state-of-the-art
                    'llama3.1:405b' model.
                    HF</p>

                <hr class="major"/>

                <h2 id="running-the-model">Running the model</h2>

                <p>When you have chosen your model it's time to use the Ollama CLI to pull it on your computer.</p>
                <ul>
                    <li>To download the model do <code>ollama pull &lt;model_name&gt;</code> ;</li>
                    <li>Then list installed models using <code>ollama list</code> ;</li>
                    <li>When ready, test the model locally by doing <code>ollama run &lt;model_name&gt;</code> which
                        will start a conversation with the LLM ;
                    </li>
                </ul>

                <hr class="major"/>

                <h2 id="installing-yacana">Installing Yacana</h2>
                <p style="text-align: center;">
						<span class="image"><img style="width: 50%;" src="../images/yacana_round_small.png"
                                                 alt=""/></span>
                </p>
                <pre><code class="language-python">
pip install yacana
					</code></pre>

                <hr class="major"/>

                <h2 id="imports">Imports</h2>
                <p>When using other frameworks 'import hell' quickly appears. To prevent this bothersome problem we
                    propose that you always import all of Yacana's modules and when finished developing let the IDE
                    remove the unused imports.
                    Unused imports generally appear grayed. Thus we recommend that you prepend these imports in all
                    your files and clean them later. This way the IDE will have auto-completion available and will
                    help you develop 10 times faster.</p>
                <pre><code class="language-python">
from yacana import Agent, Task, Tool, Message, MessageRole, GroupSolve, EndChat, EndChatMode, ModelSettings, LoggerManager, ToolError, MaxToolErrorIter
					</code></pre>


                <div style="text-align: center; margin-top: 50px;">
                    <h4>Pagination</h4>
                    <ul class="pagination">
                        <li><span class="button disabled">Prev</span></li>

                        <li><a href="agents_and_tasks.html#creating-an-agent" class="button">Next</a></li>
                    </ul>
                </div>
            </section>

        </div>
    </div>

    <!-- Sidebar -->
    <div id="sidebar">
        <div class="inner">

            <!-- Search -->
            <section id="search" class="alt">
                <form method="post" action="#">
                    <input type="text" name="query" id="query" placeholder="Search"/>
                </form>
            </section>

            <!-- Menu -->
            <nav class="menu">
                <header class="major">
                    <h2>Menu</h2>
                </header>
                <ul>
                    <li><a href="../index.html">Homepage</a></li>
                    <li>
                        <span class="opener">I. Installation</span>
                        <ul>
                            <li><a href="installation.html#installing-ollama">Installing Ollama</a></li>
                            <li><a href="installation.html#choosing-an-llm-model">Choosing an LLM model</a>
                            </li>
                            <li><a href="installation.html#running-the-model">Running the model</a></li>
                            <li><a href="installation.html#installing-yacana">Installing Yacana</a></li>
                            <li><a href="installation.html#imports">Imports</a></li>
                        </ul>
                    </li>
                    <li>
                        <span class="opener">II. Agents & Tasks</span>
                        <ul>
                            <li><a href="agents_and_tasks.html#creating-an-agent">Creating an Agent</a></li>
                            <li><a href="agents_and_tasks.html#basic-roleplay">Basic roleplay</a></li>
                            <li><a href="agents_and_tasks.html#creating-tasks">Creating Tasks</a></li>
                            <li><a href="agents_and_tasks.html#getting-the-result-of-a-task">Getting the
                                result of a Task</a></li>
                            <li><a href="agents_and_tasks.html#chaining-tasks">Chaining Tasks</a></li>
                            <li><a href="agents_and_tasks.html#logging-levels">Logging levels</a></li>
                            <li><a href="agents_and_tasks.html#configuring-llms-settings">Configuring LLM's
                                settings</a></li>
                        </ul>
                    </li>
                    <li>
                        <span class="opener">III. Routing</span>
                        <ul>
                            <li><a href="routing.html#concepts-of-routing">Concepts of routing</a></li>
                            <li><a href="routing.html#self-reflection-routing">Self-reflection routing</a>
                            </li>
                            <li><a href="routing.html#cleaning-history">Cleaning history</a></li>
                            <li><a href="routing.html#routing-demonstration">Routing demonstration</a></li>
                        </ul>
                    </li>
                    <li>
                        <span class="opener">IV. Managing Agents history</span>
                        <ul>
                            <li><a href="managing_agent_history.html#printing-history">Printing history</a>
                            </li>
                            <li><a href="managing_agent_history.html#creating-and-loading-checkpoints">Creating
                                and loading checkpoints</a></li>
                            <li><a href="managing_agent_history.html#Zero-prompt-shot-vs-multi-prompt-shot">Zero-prompt
                                shot vs multi-prompt shot</a></li>
                            <li><a href="managing_agent_history.html#saving-agent-state">Saving Agent
                                state</a></li>
                        </ul>
                    </li>
                    <li>
                        <span class="opener">V. Tool calling</span>
                        <ul>
                            <li><a href="tool_calling.html#concept-of-calling-tools">Concepts of calling
                                tools</a></li>
                            <li><a href="tool_calling.html#writing-good-tool-prompts">Writing good tool
                                prompts</a></li>
                            <li><a href="tool_calling.html#calling-a-tool">Calling a tool</a></li>
                            <li><a href="tool_calling.html#improving-tool-calling-results">Improving
                                tool-calling results</a></li>
                            <li><a href="tool_calling.html#optional-tools">Optional tools</a></li>
                            <li><a href="tool_calling.html#assigning-multiple-tools">Assigning multiple
                                Tools</a></li>
                        </ul>
                    </li>
                    <li>
                        <span class="opener">VI. Dual-agents chat</span>
                        <ul>
                            <li><a href="dual_agents_chat.html#stopping-chat-using-maximum-iterations">Stopping
                                chat using 'maximum iterations'</a></li>
                            <li><a href="dual_agents_chat.html#letting-agents-end-the-chat">Letting Agents end
                                the chat</a></li>
                            <li><a href="dual_agents_chat.html#controlling-the-shift-message">Controlling the
                                Shift Message</a></li>
                            <li><a href="dual_agents_chat.html#using-tools-in-chat">Using tools in chat</a>
                            </li>
                        </ul>
                    </li>
                    <li><a href="multi_agents_chat.html#multi-agents-chat">VII. Multi-agents chat</a></li>
                </ul>
                <br>
                <ul>
                    <li>
                        <a href="classes.html">
                            <span style="display: inline" class="icon solid fa-cog">
                                <span class="label">
                                    Technical Documentation
                                </span>
                                Technical Documentation
                            </span>
                        </a>
                    </li>
                </ul>
            </nav>

            <!-- Section -->
            <section>
                <header class="major">
                    <h2>Related Youtube video</h2>
                </header>
                <div class="mini-posts">
                    <article>
                        <a href="#" class="image"><img src="../images/youtube_down.jpg" alt=""/></a>
                        <p>Youtube video for this section is still under creation. Please be patient ^^</p>
                    </article>
                </div>
            </section>

            <!-- Section -->
            <section>
                <nav class="menu">
                    <header class="major">
                        <h2>Page menu</h2>
                    </header>
                    <ul>
                        <li><a href="installation.html#installing-ollama">Installing Ollama</a></li>
                        <li><a href="installation.html#choosing-an-llm-model">Choosing an LLM model</a>
                        </li>
                        <li><a href="installation.html#running-the-model">Running the model</a></li>
                        <li><a href="installation.html#installing-yacana">Installing Yacana</a></li>
                        <li><a href="installation.html#imports">Imports</a></li>
                    </ul>
                </nav>
            </section>

            <!-- Footer -->
            <footer id="footer">
                <p class="copyright">&copy; Emilien Lancelot. All rights reserved.<br>
                    Design: <a href="https://html5up.net">HTML5UP</a>.</p>
            </footer>

        </div>
    </div>

</div>

<!-- Scripts -->
<script src="../assets/js/jquery.min.js"></script>
<script src="../assets/js/browser.min.js"></script>
<script src="../assets/js/breakpoints.min.js"></script>
<script src="../assets/js/util.js"></script>
<script src="../assets/js/main.js"></script>

</body>

</html>